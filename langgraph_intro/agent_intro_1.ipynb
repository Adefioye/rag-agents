{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "872a2e50-6834-44b0-9326-1cabffc0161a",
   "metadata": {},
   "source": [
    "# Expreimenting with the langraph doc starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "704508cd-7230-4eb6-bc14-fe824a8a7f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 4 * 5?', id='f9250710-5984-466a-b0cb-04115b891624'),\n",
       " AIMessage(content='4 * 5 equals 20.', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 15, 'total_tokens': 23}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}, id='0912a85e-61ec-4b3a-a0c0-7f47ef9afc98')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import END, MessageGraph\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "graph = MessageGraph()\n",
    "\n",
    "graph.add_node(\"oracle\", model)\n",
    "graph.add_edge(\"oracle\", END)\n",
    "\n",
    "graph.set_entry_point(\"oracle\")\n",
    "\n",
    "runnable = graph.compile()\n",
    "runnable.invoke(HumanMessage(\"What is 4 * 5?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d96cdb6-85fb-4787-8bf0-61255afeb96a",
   "metadata": {},
   "source": [
    "# Introduction to Conditional edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a9efde4-7d19-4235-a2b7-776b162ea830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State that goes into invoke tool:  [HumanMessage(content='What is 4 * 5?', id='0bb8dc81-1c43-4909-a4a2-8a90ae20ef5d'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_eOuorOFtJFKmNoEcTwf0pJhS', 'function': {'arguments': '{\"first_num\":4,\"second_num\":5}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 68, 'total_tokens': 87}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='b3c29ac8-32cd-4443-b85d-2c50ef2d8b27')]\n",
      "Result on function arguments:  20\n",
      "Tool message:  content='20' tool_call_id='call_eOuorOFtJFKmNoEcTwf0pJhS'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 4 * 5?', id='0bb8dc81-1c43-4909-a4a2-8a90ae20ef5d'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_eOuorOFtJFKmNoEcTwf0pJhS', 'function': {'arguments': '{\"first_num\":4,\"second_num\":5}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 68, 'total_tokens': 87}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='b3c29ac8-32cd-4443-b85d-2c50ef2d8b27'),\n",
       " ToolMessage(content='20', id='7093c1b0-0ecf-4e3c-b2c2-d4a4735c83f3', tool_call_id='call_eOuorOFtJFKmNoEcTwf0pJhS')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "from typing import List\n",
    "\n",
    "@tool\n",
    "def multiply(first_num: int, second_num: int):\n",
    "    \"\"\"\n",
    "    Multiply two numbers together\n",
    "    \"\"\"\n",
    "    return first_num * second_num\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "model_with_tools = model.bind(tools=[convert_to_openai_tool(multiply)])\n",
    "\n",
    "graph = MessageGraph()\n",
    "\n",
    "def invoke_model(state: List[BaseMessage]):\n",
    "    return model_with_tools.invoke(state)\n",
    "\n",
    "graph.add_node(\"oracle\", invoke_model)\n",
    "\n",
    "def invoke_tool(state: List[BaseMessage]):\n",
    "    print(\"State that goes into invoke tool: \", state)\n",
    "    tool_calls = state[-1].additional_kwargs.get(\"tool_calls\", [])\n",
    "    multiply_call = None\n",
    "\n",
    "    for tool_call in tool_calls:\n",
    "        if tool_call.get(\"function\").get(\"name\") == \"multiply\":\n",
    "            multiply_call = tool_call\n",
    "\n",
    "    if multiply_call is None:\n",
    "        raise Exception(\"No adder input found.\")\n",
    "\n",
    "    res = multiply.invoke(\n",
    "        json.loads(multiply_call.get(\"function\").get(\"arguments\"))\n",
    "    )\n",
    "    print(\"Result on function arguments: \", res)\n",
    "    print(\"Tool message: \", ToolMessage(\n",
    "        tool_call_id=multiply_call.get(\"id\"),\n",
    "        content=res\n",
    "    ))\n",
    "    return ToolMessage(\n",
    "        tool_call_id=multiply_call.get(\"id\"),\n",
    "        content=res\n",
    "    )\n",
    "\n",
    "graph.add_node(\"multiply\", invoke_tool)\n",
    "\n",
    "graph.add_edge(\"multiply\", END)\n",
    "\n",
    "graph.set_entry_point(\"oracle\")\n",
    "\n",
    "# Router to end if no tool call or use tool if there is tool call\n",
    "def router(state: List[BaseMessage]):\n",
    "    tool_calls = state[-1].additional_kwargs.get(\"tool_calls\", [])\n",
    "    if len(tool_calls):\n",
    "        return \"multiply\"\n",
    "    else:\n",
    "        return \"end\"\n",
    "        \n",
    "# Crucial in order to avoid oracle node being a dead end\n",
    "graph.add_conditional_edges(\"oracle\", router, {\n",
    "    \"multiply\": \"multiply\",\n",
    "    \"end\": END,\n",
    "})\n",
    "runnable = graph.compile()\n",
    "\n",
    "# Maths related question call tool. Especially multiply function\n",
    "runnable.invoke(HumanMessage(\"What is 4 * 5?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3ad5546-59c2-4669-abf0-3734b930ee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is your name?', id='857c4365-383a-4c6d-b1b2-28d37ed332b6'),\n",
       " AIMessage(content='My name is Assistant. How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 65, 'total_tokens': 78}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}, id='b9587ec4-17e7-4454-b0f7-dbe9e6304e74')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-maths related question does not call tool\n",
    "runnable.invoke(HumanMessage(\"What is your name?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1143c1-a123-4560-8d1d-eb8f06ab69ae",
   "metadata": {},
   "source": [
    "# Agent Executor from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd162f5-78d7-4d77-91fb-504661b29b54",
   "metadata": {},
   "source": [
    "First we need to install the packages required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d511c0-b759-436f-a780-630d5ad87569",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet -U langchain langchain_openai langchainhub tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d734bbdb-89ed-40f7-9b57-55df78c2cd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPEN API KEY:  ········\n",
      "TAVILY API KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OPEN API KEY: \")\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass(\"TAVILY API KEY: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717b5c26-a56e-4179-868c-6e16c1bc3fd6",
   "metadata": {},
   "source": [
    "Optionally, we can set API key for LangSmith tracing, which will give us best-in-class observability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26179553-8810-41c8-a78a-89a701530e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LangSmith API Key:  ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass(\"LangSmith API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c1e0d-646e-4024-8346-5aab14e2e07c",
   "metadata": {},
   "source": [
    "# Create a Langchain agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93280b32-6f87-4762-b051-79379dcac94c",
   "metadata": {},
   "source": [
    "First, we will create the LangChain agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b9050d0-09cf-4edb-b165-f39f90e421b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "# print(\"Prompt: \", prompt, end=\"\\n\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", streaming=True)\n",
    "\n",
    "agent_runnable = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "# print(\"Agent runnable: \", agent_runnable, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fa206b-ffcf-498f-8d00-ff603a4fba14",
   "metadata": {},
   "source": [
    "# Define the graph state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc9a4c4-1d72-4c02-bd39-ec8e4f8d2ef0",
   "metadata": {},
   "source": [
    "We now define the graph state. The state for the traditional LangChain agent has a few attributes:\n",
    "\n",
    "1. `input`: This is the input string representing the main ask from the user, passed in as input.\n",
    "2. `chat_history`: This is any previous conversation messages, also passed in as input.\n",
    "3. `intermediate_steps`: This is list of actions and corresponding observations that the agent takes over time. This is updated each iteration of the agent.\n",
    "4. `agent_outcome`: This is the response from the agent, either an AgentAction or AgentFinish. The AgentExecutor should finish when this is an AgentFinish, otherwise it should call the requested tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e61127bd-7423-405d-b0a5-5d33912d668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    chat_history: list[BaseMessage]\n",
    "    agent_outcome: Union[AgentAction, AgentFinish, None]\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b5b719-e8e6-4750-9d3c-cf092354fd0e",
   "metadata": {},
   "source": [
    "# Define the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbb6e367-74d8-4719-895e-00f402b14a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.agents import AgentFinish\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
    "# Create the tool executor\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "# Define the agent\n",
    "def run_agent(data):\n",
    "    agent_outcome = agent_runnable.invoke(data)\n",
    "    return {\"agent_outcome\": agent_outcome}\n",
    "\n",
    "# Define the function to execute tools\n",
    "def execute_tools(data):\n",
    "    agent_action = data[\"agent_outcome\"]\n",
    "    output = tool_executor.invoke(agent_action)\n",
    "    return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
    "\n",
    "# Define logic that will be used to determine which conditional edge to go down\n",
    "def should_continue(data):\n",
    "    if isinstance(data[\"agent_outcome\"], AgentFinish):\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9230ac2e-e64c-4cdb-8313-27b6737a218c",
   "metadata": {},
   "source": [
    "# Define the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9582fa93-c318-408f-b3c7-14a9e2066771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "# Define two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", run_agent)\n",
    "workflow.add_node(\"action\", execute_tools)\n",
    "\n",
    "# Set entry point as \"agent\"\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add a normal edge from `tools` to `agent`\n",
    "# This means after tools is called, `agent` node is called next\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# Compile workflow to runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "170e4ea5-2bfb-484d-8b46-671456ef0667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of each stream:  {'agent_outcome': AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'})])}\n",
      "----\n",
      "Values of each stream:  {'intermediate_steps': [(AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'})]), '[{\\'url\\': \\'https://weather.com/weather/tenday/l/San Francisco CA USCA0987:1:US\\', \\'content\\': \"Comfy & Cozy\\\\nThat\\'s Not What Was Expected\\\\nOutside\\\\n\\'No-Name Storms\\' In Florida\\\\nGifts From On High\\\\nWhat To Do For Wheezing\\\\nSurviving The Season\\\\nStay Safe\\\\nAir Quality Index\\\\nAir quality is considered satisfactory, and air pollution poses little or no risk.\\\\n Health & Activities\\\\nSeasonal Allergies and Pollen Count Forecast\\\\nNo pollen detected in your area\\\\nCold & Flu Forecast\\\\nFlu risk is low in your area\\\\nWe recognize our responsibility to use data and technology for good. recents\\\\nSpecialty Forecasts\\\\n10 Day Weather-San Francisco, CA\\\\nToday\\\\nMon 18 | Day\\\\nConsiderable cloudiness. Tue 19\\\\nTue 19 | Day\\\\nLight rain early...then remaining cloudy with showers in the afternoon. Wed 27\\\\nWed 27 | Day\\\\nOvercast with rain showers at times.\"}]')]}\n",
      "----\n",
      "Values of each stream:  {'agent_outcome': AgentFinish(return_values={'output': \"The weather in San Francisco today is showing considerable cloudiness, with light rain in the early morning and remaining cloudy with showers in the afternoon. If you'd like to see a detailed forecast, you can visit [this link](https://weather.com/weather/tenday/l/San%20Francisco%20CA%20USCA0987:1:US).\"}, log=\"The weather in San Francisco today is showing considerable cloudiness, with light rain in the early morning and remaining cloudy with showers in the afternoon. If you'd like to see a detailed forecast, you can visit [this link](https://weather.com/weather/tenday/l/San%20Francisco%20CA%20USCA0987:1:US).\")}\n",
      "----\n",
      "Values of each stream:  {'input': 'what is the weather in sf', 'chat_history': [], 'agent_outcome': AgentFinish(return_values={'output': \"The weather in San Francisco today is showing considerable cloudiness, with light rain in the early morning and remaining cloudy with showers in the afternoon. If you'd like to see a detailed forecast, you can visit [this link](https://weather.com/weather/tenday/l/San%20Francisco%20CA%20USCA0987:1:US).\"}, log=\"The weather in San Francisco today is showing considerable cloudiness, with light rain in the early morning and remaining cloudy with showers in the afternoon. If you'd like to see a detailed forecast, you can visit [this link](https://weather.com/weather/tenday/l/San%20Francisco%20CA%20USCA0987:1:US).\"), 'intermediate_steps': [(AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'})]), '[{\\'url\\': \\'https://weather.com/weather/tenday/l/San Francisco CA USCA0987:1:US\\', \\'content\\': \"Comfy & Cozy\\\\nThat\\'s Not What Was Expected\\\\nOutside\\\\n\\'No-Name Storms\\' In Florida\\\\nGifts From On High\\\\nWhat To Do For Wheezing\\\\nSurviving The Season\\\\nStay Safe\\\\nAir Quality Index\\\\nAir quality is considered satisfactory, and air pollution poses little or no risk.\\\\n Health & Activities\\\\nSeasonal Allergies and Pollen Count Forecast\\\\nNo pollen detected in your area\\\\nCold & Flu Forecast\\\\nFlu risk is low in your area\\\\nWe recognize our responsibility to use data and technology for good. recents\\\\nSpecialty Forecasts\\\\n10 Day Weather-San Francisco, CA\\\\nToday\\\\nMon 18 | Day\\\\nConsiderable cloudiness. Tue 19\\\\nTue 19 | Day\\\\nLight rain early...then remaining cloudy with showers in the afternoon. Wed 27\\\\nWed 27 | Day\\\\nOvercast with rain showers at times.\"}]')]}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"input\": \"what is the weather in sf\", \"chat_history\": []}\n",
    "for s in app.stream(inputs):\n",
    "    print(\"Values of each stream: \", list(s.values())[0])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f004cab-f65f-44f4-881d-66a99a11246a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-and-agents-2",
   "language": "python",
   "name": "rag-and-agents-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
