{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acf813cc-8afd-4675-be27-1f6ad7bbdd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet -U langchain langchain_openai langchainhub tavily-python langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5861696f-e55e-4b1b-8e28-8b0df0eff2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: ········\n",
      "Tavily API Key: ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbe7465-be3f-4146-9ec2-48ff6d68eea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LangSmith API Key: ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a416b-9126-4e7d-b603-1d5ccdc7fb62",
   "metadata": {},
   "source": [
    "# Create a Langchain Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8791fd80-5f25-4482-a770-e5f7849de0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", streaming=True)\n",
    "\n",
    "# Construct the OpenAI Functions agent\n",
    "agent_runnable = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3039697-b0e1-4436-b0bf-6839e56658e7",
   "metadata": {},
   "source": [
    "# Define the graph state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b8fca14-6069-495d-a52a-ff8aa0d3633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The input string\n",
    "    input: str\n",
    "    # The list of previous messages in the conversation\n",
    "    chat_history: list[BaseMessage]\n",
    "    # The outcome of a given call to the agent\n",
    "    # Needs `None` as a valid type, since this is what this will start as\n",
    "    agent_outcome: Union[AgentAction, AgentFinish, None]\n",
    "    # List of actions and corresponding observations\n",
    "    # Here we annotate this with `operator.add` to indicate that operations to\n",
    "    # this state should be ADDED to the existing values (not overwrite it)\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1520522f-0c26-45ec-82dd-b824ca468cbf",
   "metadata": {},
   "source": [
    "# Define the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4a4b50e-a615-428b-87bb-b93ac14f2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.agents import AgentFinish\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
    "\n",
    "# This a helper class we have that is useful for running tools\n",
    "# It takes in an agent action and calls that tool and returns the result\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "\n",
    "# Define the agent\n",
    "def run_agent(data):\n",
    "    agent_outcome = agent_runnable.invoke(data)\n",
    "    return {\"agent_outcome\": agent_outcome}\n",
    "\n",
    "\n",
    "# Define the function to execute tools\n",
    "def execute_tools(data):\n",
    "    # Get the most recent agent_outcome - this is the key added in the `agent` above\n",
    "    agent_action = data[\"agent_outcome\"]\n",
    "    output = tool_executor.invoke(agent_action)\n",
    "    return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
    "\n",
    "# Define logic that will be used to determine which conditional edge to go down\n",
    "def should_continue(data):\n",
    "    # If the agent outcome is an AgentFinish, then we return `exit` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    if isinstance(data[\"agent_outcome\"], AgentFinish):\n",
    "        return \"end\"\n",
    "    # Otherwise, an AgentAction is returned\n",
    "    # Here we return `continue` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb8a23-7915-4d3a-ae3c-ec61b56b62d6",
   "metadata": {},
   "source": [
    "# Define the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7dbc14e-e14e-494c-a43f-95b66d2a0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", run_agent)\n",
    "workflow.add_node(\"action\", execute_tools)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27604a85-3a43-4850-8a88-e964fd96970a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'})])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'})]), \"[{'url': 'https://www.accuweather.com/en/us/san-francisco/94103/current-weather/347629', 'content': 'Get the latest weather conditions and outlook for San Francisco, CA, including temperature, humidity, wind, pressure, and cloud cover. See alerts, sunrise and sunset times, and historical data for the city.'}]\")]}\n",
      "----\n",
      "{'agent_outcome': AgentFinish(return_values={'output': 'You can find the latest weather conditions and outlook for San Francisco, CA, including temperature, humidity, wind, pressure, and cloud cover on [AccuWeather](https://www.accuweather.com/en/us/san-francisco/94103/current-weather/347629).'}, log='You can find the latest weather conditions and outlook for San Francisco, CA, including temperature, humidity, wind, pressure, and cloud cover on [AccuWeather](https://www.accuweather.com/en/us/san-francisco/94103/current-weather/347629).')}\n",
      "----\n",
      "{'input': 'what is the weather in sf', 'chat_history': [], 'agent_outcome': AgentFinish(return_values={'output': 'You can find the latest weather conditions and outlook for San Francisco, CA, including temperature, humidity, wind, pressure, and cloud cover on [AccuWeather](https://www.accuweather.com/en/us/san-francisco/94103/current-weather/347629).'}, log='You can find the latest weather conditions and outlook for San Francisco, CA, including temperature, humidity, wind, pressure, and cloud cover on [AccuWeather](https://www.accuweather.com/en/us/san-francisco/94103/current-weather/347629).'), 'intermediate_steps': [(AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'})]), \"[{'url': 'https://www.accuweather.com/en/us/san-francisco/94103/current-weather/347629', 'content': 'Get the latest weather conditions and outlook for San Francisco, CA, including temperature, humidity, wind, pressure, and cloud cover. See alerts, sunrise and sunset times, and historical data for the city.'}]\")]}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"input\": \"what is the weather in sf\", \"chat_history\": []}\n",
    "for s in app.stream(inputs):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2e756f-0753-41c4-814b-4f67a045d57c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53e07847-fbc2-4a3f-b89a-e2e1794575c3",
   "metadata": {},
   "source": [
    "# Starting to test Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "704508cd-7230-4eb6-bc14-fe824a8a7f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 4 * 5?', id='f9250710-5984-466a-b0cb-04115b891624'),\n",
       " AIMessage(content='4 * 5 equals 20.', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 15, 'total_tokens': 23}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}, id='0912a85e-61ec-4b3a-a0c0-7f47ef9afc98')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import END, MessageGraph\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "graph = MessageGraph()\n",
    "\n",
    "graph.add_node(\"oracle\", model)\n",
    "graph.add_edge(\"oracle\", END)\n",
    "\n",
    "graph.set_entry_point(\"oracle\")\n",
    "\n",
    "runnable = graph.compile()\n",
    "runnable.invoke(HumanMessage(\"What is 4 * 5?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d96cdb6-85fb-4787-8bf0-61255afeb96a",
   "metadata": {},
   "source": [
    "# Introduction to Conditional edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a9efde4-7d19-4235-a2b7-776b162ea830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State that goes into invoke tool:  [HumanMessage(content='What is 4 * 5?', id='0bb8dc81-1c43-4909-a4a2-8a90ae20ef5d'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_eOuorOFtJFKmNoEcTwf0pJhS', 'function': {'arguments': '{\"first_num\":4,\"second_num\":5}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 68, 'total_tokens': 87}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='b3c29ac8-32cd-4443-b85d-2c50ef2d8b27')]\n",
      "Result on function arguments:  20\n",
      "Tool message:  content='20' tool_call_id='call_eOuorOFtJFKmNoEcTwf0pJhS'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 4 * 5?', id='0bb8dc81-1c43-4909-a4a2-8a90ae20ef5d'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_eOuorOFtJFKmNoEcTwf0pJhS', 'function': {'arguments': '{\"first_num\":4,\"second_num\":5}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 68, 'total_tokens': 87}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='b3c29ac8-32cd-4443-b85d-2c50ef2d8b27'),\n",
       " ToolMessage(content='20', id='7093c1b0-0ecf-4e3c-b2c2-d4a4735c83f3', tool_call_id='call_eOuorOFtJFKmNoEcTwf0pJhS')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "from typing import List\n",
    "\n",
    "@tool\n",
    "def multiply(first_num: int, second_num: int):\n",
    "    \"\"\"\n",
    "    Multiply two numbers together\n",
    "    \"\"\"\n",
    "    return first_num * second_num\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "model_with_tools = model.bind(tools=[convert_to_openai_tool(multiply)])\n",
    "\n",
    "graph = MessageGraph()\n",
    "\n",
    "def invoke_model(state: List[BaseMessage]):\n",
    "    return model_with_tools.invoke(state)\n",
    "\n",
    "graph.add_node(\"oracle\", invoke_model)\n",
    "\n",
    "def invoke_tool(state: List[BaseMessage]):\n",
    "    print(\"State that goes into invoke tool: \", state)\n",
    "    tool_calls = state[-1].additional_kwargs.get(\"tool_calls\", [])\n",
    "    multiply_call = None\n",
    "\n",
    "    for tool_call in tool_calls:\n",
    "        if tool_call.get(\"function\").get(\"name\") == \"multiply\":\n",
    "            multiply_call = tool_call\n",
    "\n",
    "    if multiply_call is None:\n",
    "        raise Exception(\"No adder input found.\")\n",
    "\n",
    "    res = multiply.invoke(\n",
    "        json.loads(multiply_call.get(\"function\").get(\"arguments\"))\n",
    "    )\n",
    "    print(\"Result on function arguments: \", res)\n",
    "    print(\"Tool message: \", ToolMessage(\n",
    "        tool_call_id=multiply_call.get(\"id\"),\n",
    "        content=res\n",
    "    ))\n",
    "    return ToolMessage(\n",
    "        tool_call_id=multiply_call.get(\"id\"),\n",
    "        content=res\n",
    "    )\n",
    "\n",
    "graph.add_node(\"multiply\", invoke_tool)\n",
    "\n",
    "graph.add_edge(\"multiply\", END)\n",
    "\n",
    "graph.set_entry_point(\"oracle\")\n",
    "\n",
    "# Router to end if no tool call or use tool if there is tool call\n",
    "def router(state: List[BaseMessage]):\n",
    "    tool_calls = state[-1].additional_kwargs.get(\"tool_calls\", [])\n",
    "    if len(tool_calls):\n",
    "        return \"multiply\"\n",
    "    else:\n",
    "        return \"end\"\n",
    "        \n",
    "# Crucial in order to avoid oracle node being a dead end\n",
    "graph.add_conditional_edges(\"oracle\", router, {\n",
    "    \"multiply\": \"multiply\",\n",
    "    \"end\": END,\n",
    "})\n",
    "runnable = graph.compile()\n",
    "\n",
    "# Maths related question call tool. Especially multiply function\n",
    "runnable.invoke(HumanMessage(\"What is 4 * 5?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3ad5546-59c2-4669-abf0-3734b930ee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is your name?', id='857c4365-383a-4c6d-b1b2-28d37ed332b6'),\n",
       " AIMessage(content='My name is Assistant. How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 65, 'total_tokens': 78}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}, id='b9587ec4-17e7-4454-b0f7-dbe9e6304e74')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-maths related question does not call tool\n",
    "runnable.invoke(HumanMessage(\"What is your name?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df62a9d-e2ae-48b6-b590-1f30e4779978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
